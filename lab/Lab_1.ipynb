{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQlm06wSn6DE"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this lab session we will provide a quick introduction to the libraries we often use in the labs. We will install the required modules and perform a quick verificaiton that the installed packages work correctly.\n",
        "\n",
        "At the end of the lab, we ask of you to provide an instance in your line of work where you would like to apply the techniques you will learn in this Explainable AI course. It could be a specific use case where you would like to explain how a model performs a specific task, it could be a general overview where you think explainability is especially important in your domain/workplace, what your current view of explainable AI is, etc. This is an open ended question where you are free to write whatever you please.\n",
        "\n",
        "From this last part of the lab, there is an option to perform an optional project at the end of the course. The project is as well open ended and not mandatory for a grade in the course. Our intention with this project option is to provide a platform for you to discuss your idea during the interactive sessions and try to provide an explainable AI model. You are not required to provide any models or datasets, if there are privacy or NDA concerns, it is only for your own benefit.\n",
        "\n",
        "If you decide to try and make a project, try and explain the problem you are trying to solve and how explainability might help with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2zhUiEKlrre"
      },
      "source": [
        "# Installation\n",
        "\n",
        "We have the cell below to run if you would like to install the packages via the notebook. If you want more control of where the packages are stored, we have a pip *requirements.txt* file next to this notebook on the courses blackboard page. **We recommend you install via the requirements.txt file** if you are using your own machine and have Python 3.11 installed.\n",
        "\n",
        "If you are using Colab, then running the cell below should install everything necessary for the labs. We will reuse this cell containing installations in the future labs as well. You might have to restart the session after installation by pressing **Runtime** -> **Restart Session** to make everything compatible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O_s2ddpltci"
      },
      "outputs": [],
      "source": [
        "%pip install -U scikit-learn==1.4.1.post1 shap==0.45.0 lime==0.2.0.1 tensorflow==2.16.1 tf-keras==2.16.0 graphviz==0.20.2 dtreeviz==2.2.2 eli5==0.13.0 xgboost==2.0.3 pandas==2.2.1 seaborn==0.13.2 tf-keras-vis==0.8.6 numpy==1.26.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vfQyuLPoLr-"
      },
      "source": [
        "## SciKit Learn\n",
        "\n",
        "In some of the labs we will use the well known scikit-learn module.\n",
        "It contains many algorithms, models, datasets, evaluation methods, and many other things, from the machine learning domain.\n",
        "\n",
        "We will try and stick to the basic functionalities from the library in the course labs. However, we feel it to be of importance to go through the basic syntax that all models follow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KlzJ5LCZ3dE"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xqu09lydrzF"
      },
      "source": [
        "Creating a logistic regression model to train on the iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM9n5q6udtDh"
      },
      "outputs": [],
      "source": [
        "lor = LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IoEpw_-dwog"
      },
      "source": [
        "Load the iris dataset and split into test and train subsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlyCIv-idxRv"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(iris['data'], iris['target'], random_state=42, test_size=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etk6uT1jd17A"
      },
      "source": [
        "Training a model on a dataset calls for the fit function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCgDdMpvd3hz"
      },
      "outputs": [],
      "source": [
        "lor.fit(X_iris_train, y_iris_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuqQxRG5d49j"
      },
      "source": [
        "Predicting using the model is performed using predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQIlapgfd6Am"
      },
      "outputs": [],
      "source": [
        "y_pred = lor.predict(X_iris_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eQKuqtJd7Yg"
      },
      "source": [
        "For a simple accuracy measure of the classification, we can use the accuracy score function available in the **sklearn.metrics** module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-1VnUafd8pP"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_iris_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6eRgg8gczdX"
      },
      "source": [
        "As previously stated, all models follow the same fit and predict scheme which can be seen for this linear regression model on a diabetes dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz0Rkyl8c8vb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "lir = LinearRegression()\n",
        "diabetes = load_diabetes()\n",
        "X_train, X_test, y_train, y_test = train_test_split(diabetes['data'], diabetes['target'], random_state=42, test_size=0.4)\n",
        "\n",
        "lir.fit(X_train, y_train)\n",
        "y_pred = lir.predict(X_test)\n",
        "mean_absolute_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05JvSvKBk0LH"
      },
      "source": [
        "## SHAP\n",
        "A package to perform local model-agnostic techniques, to explain individual predictions of a model. A quick example of the linear regressor on the diabetes dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfaX0RuBtFwb"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "mask = shap.maskers.Independent(X_train)\n",
        "lr_explainer = shap.LinearExplainer(lir, mask, feature_names=diabetes.feature_names)\n",
        "lr_shap_values = lr_explainer.shap_values(X_test)\n",
        "lr_shaps = lr_explainer(X_test)\n",
        "\n",
        "shap.decision_plot(lr_explainer.expected_value, lr_shap_values[[6,8,10]], diabetes.feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Z1cRtlk18b"
      },
      "source": [
        "## LIME\n",
        "A package to perform local model-agnostic techniques. A quick example using the logistic regressor for the iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EccQs5ttHA8"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_iris_train, feature_names = iris.feature_names, kernel_width=3, verbose=False)\n",
        "exp = lime_explainer.explain_instance(X_iris_test[28], lor.predict_proba, num_features=5)\n",
        "exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-qyg8vyk_KS"
      },
      "source": [
        "## Pandas\n",
        "Common package used in data science and machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pctEKF1otIFc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame([[1,2,3],[6,5,4]], columns=['col1', 'col2','col3'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz7ABpvplEqj"
      },
      "source": [
        "## xgboost\n",
        "A library that implements the use of ensemble trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJbtb23etJfF"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "xgb = xgboost.XGBClassifier(n_estimators=500, max_depth=4)\n",
        "xgb.fit(X_iris_train, y_iris_train)\n",
        "print(accuracy_score(xgb.predict(X_iris_test), y_iris_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DZl5YMBk26L"
      },
      "source": [
        "## dtreeviz\n",
        "A visualization tool for displaying decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oed_bCaWtMvC"
      },
      "outputs": [],
      "source": [
        "import dtreeviz\n",
        "viz = dtreeviz.model(xgb, X_iris_train, y_iris_train,\n",
        "                     target_name='class', tree_index=1,\n",
        "                     feature_names=iris.feature_names,\n",
        "                     class_names=iris.target_names)\n",
        "viz.view(fontname='DejaVu Sans')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm7vrsK-oLuG"
      },
      "source": [
        "## Tensorflow and Keras\n",
        "\n",
        "For the last lab, we will venture into neural networks and we have prepared our lab using Keras and Tensorflow. If you have experiences with this library, or any of the other libraries, it should be fairly straight forward to follow the lab. We will provide pre-defined models and you do not have to implement much related to the networks themselves.\n",
        "\n",
        "If you do not have much experience with the framework, or neural networks in general, it might not be necessary for you to fully understand all of the code.\n",
        "Most of the code we provide and should require little hands on work from you.\n",
        "\n",
        "However, we do still recommend you to go through some basic examples available at the [Keras homepage](https://keras.io/examples/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb8icPD0tU_3"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5hrsy_ioqXN"
      },
      "source": [
        "# Overview of the remaining labs\n",
        "\n",
        "Lab 2 - In this lab, we will focus on interpretable models. Traditional statistical models, such as linear regression, are usually referred to as intrisically interpretable models as they are easily understood what they have learned and how the perform their actions.\n",
        "\n",
        "Lab 3 - Here, we will venture through global model-agnostic methods.\n",
        "We will identify the feature importance of datasets using feature importance permutation and go through thte use of global surrogate models.\n",
        "\n",
        "Lab 4 - Local model-agnostic methods is the topic for this lab. SHAP and LIME will be used to explain individual predictions to determine the effect and importance of each feature in the model.\n",
        "\n",
        "Lab 5 - Neural networks is the final topic of the lab sessions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ6IE7spgwAb"
      },
      "source": [
        "# Your view of XAI, project idea, applications of XAI, etc.\n",
        "\n",
        "Provide an instance in your line of work where you would like to apply the techniques you will learn in this Explainable AI course. It could be a specific use case where you would like to explain how a model performs a specific task, it could be a general overview where you think explainability is especially important in your domain/workplace, what your current view of explainable AI is, etc. This is an open ended question where you are free to write whatever you please.\n",
        "\n",
        "Optionally, you could also propose a project to conduct during the course. This project is as well open ended and not mandatory for a grade in the course. Our intention with this project option is to provide a platform for you to discuss your idea during the interactive sessions and try to provide an explainable AI model. You are not required to provide any models or datasets, if there are privacy or NDA concerns, it is only for your own benefit. If you decide to try and make a project, try and explain the problem you are trying to solve and how explainability might help with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv-O1P5-tw_9"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}