{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DT8060\n",
        "## Raffaello Baluyot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NWdHEEAkUeI"
      },
      "source": [
        "# Local Model-Agnostic\n",
        "In this lab, we will try and explain a models output using local model-agnostic techniques.\n",
        "Libraries SHAP and LIME will be introduced and used on models that have been trained on the [Wine Quality dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality).\n",
        "The two models we use are logistic regression form scikit-learn and a gradient boosted classification trees using xgboost.\n",
        "\n",
        "The student is then to apply the methods and try to explain a black box model's output and identify whether improvements can be made for the explainability of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So4L6DL81IrN"
      },
      "source": [
        "## Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru56bTvVjsaG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import shap\n",
        "import lime\n",
        "import time\n",
        "import xgboost\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGLe7tezzdxv"
      },
      "source": [
        "## Load the dataset and process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsoK-h36xWyQ"
      },
      "outputs": [],
      "source": [
        "wine = pd.read_csv('../data/winequality-red.csv', sep=';')\n",
        "wine.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnctMQ10ZTw"
      },
      "source": [
        "The **quality** column is based on a sensory test ranging from 1 to 10, where a higher value is considered to be a better wine.\n",
        "We remake that column to be a binary classification problem, where 0 is a lower quality wine and 1 is a higher quality wine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghtR7lhHz7ob"
      },
      "outputs": [],
      "source": [
        "wine['quality'] = np.where(wine['quality'] > 5, 1, 0)\n",
        "wine.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIyJ18E_0ttx"
      },
      "source": [
        "Divide the dataset and train the two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWJ_8trF0t1C"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(wine.iloc[:,:11].values, wine['quality'], test_size=0.3, random_state=42)\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "xgb = xgboost.XGBClassifier(n_estimators=500, max_depth=2)\n",
        "lr.fit(X_train, Y_train)\n",
        "xgb.fit(X_train, Y_train)\n",
        "print(accuracy_score(lr.predict(X_test), Y_test))\n",
        "print(accuracy_score(xgb.predict(X_test), Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5pgoSm_5WIR"
      },
      "source": [
        "## SHAP\n",
        "Calculate the shap values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liegD__Q5Vch"
      },
      "outputs": [],
      "source": [
        "mask = shap.maskers.Independent(X_train)\n",
        "lr_explainer = shap.LinearExplainer(lr, mask, feature_names=wine.columns[:11])\n",
        "lr_shap_values = lr_explainer.shap_values(X_test)\n",
        "lr_shaps = lr_explainer(X_test)\n",
        "\n",
        "xgb_explainer = shap.TreeExplainer(xgb, X_train, feature_names=wine.columns[:11])\n",
        "xgb_shap_values = xgb_explainer.shap_values(X_test)\n",
        "xgb_shaps = xgb_explainer(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jrF_7r8C_i5"
      },
      "source": [
        "### Overall view\n",
        "To give an initial glance of the effect each feature has on the models, we can plot out the summary plot from the SHAP library.\n",
        "These plots are gathered from each individual instance.\n",
        "The produced plot sorts the features in descending order of the contribution\n",
        " it has on the classifications.\n",
        "\n",
        "It's clear that the alcohol level is the major contributor in both the models and the top 5 attributes generally agree with eachother, but the order and magnitude of their contribution differs between the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNfFFCZo-E1B"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(lr_shap_values, X_test, feature_names=wine.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0HY6uACp_tx"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(xgb_shap_values, X_test, feature_names=wine.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rgX3czDNEnB"
      },
      "source": [
        "The barplot also provides the average information of the contribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4B4n7PUNX1g"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(lr_shaps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcubaZ9tNJuN"
      },
      "source": [
        "If we divide into cohorts it provides some additional information. The features are divided into the groups where the most prominent feature contributes the most.\n",
        "\n",
        "So, when for an instance which has alcohol over 10.775 the features contrubtions are available in the red and white bars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2qc-kFDGrxE"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(lr_shaps.cohorts(2).abs.mean(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXFBH6l-NWf2"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(xgb_shaps.cohorts(2).abs.mean(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuRfVatcLSaT"
      },
      "source": [
        "### Individual instances\n",
        "When we instead look at an individual data instance and its contribution to the prediction, we have a lot of options to visualize with. In all cells below there are various graphs that visualize the same things, you can use whichever you prefer for your visual aid later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg7pLVDD6te1"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "ind = 10\n",
        "shap.force_plot(\n",
        "    lr_explainer.expected_value, lr_shap_values[ind], X_test[ind,:],\n",
        "    feature_names=wine.columns[:11]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERVxyRuiHQmT"
      },
      "outputs": [],
      "source": [
        "shap.plots.waterfall(lr_shaps[ind])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHcopXFtO5Tg"
      },
      "outputs": [],
      "source": [
        "shap.decision_plot(lr_explainer.expected_value, lr_shap_values[10], wine.columns[:11])\n",
        "\n",
        "# we can also view multiple instances at once. Comment out below to view.\n",
        "#shap.decision_plot(lr_explainer.expected_value, lr_shap_values[[6,8,10]], wine.columns[:11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErzVeJ-FLRet"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(\n",
        "    xgb_explainer.expected_value, xgb_shap_values[ind], X_test[ind,:],\n",
        "    feature_names=wine.columns[:11]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqOmw7GUM2Ti"
      },
      "outputs": [],
      "source": [
        "xgb_shaps = xgb_explainer(X_test)\n",
        "shap.plots.waterfall(xgb_shaps[ind])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UApKADbN6s4h"
      },
      "source": [
        "### Correlated Features\n",
        "Using hierarchical clustering, we can view how features are correlated to each other. This is built into shap.\n",
        "\n",
        "We can use this information to simplify, and perhaps better the model, as correlated features often divide the importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPbIuw6vH3_D"
      },
      "outputs": [],
      "source": [
        "clustering = shap.utils.hclust(X_test, Y_test)\n",
        "shap.plots.bar(lr_shaps, clustering=clustering, clustering_cutoff=0.57) # A higher cut off value means a larger distance between the features. I.e., larger means more independant and less redundant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snFs_pAr_Wwq"
      },
      "source": [
        "We see that the density feature is correlated to alcohol. If we remove density, we are likely to increase the importance of the alcohol feature.\n",
        "\n",
        "Below we remove the density feature and retrain the model. We then look into if the predictive performance has changed and we visualize the same instance as before using the SHAP library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZysyk5C_6wU"
      },
      "outputs": [],
      "source": [
        "cols = wine.drop('density', axis=1).columns\n",
        "wine_without_density = wine[cols]\n",
        "\n",
        "\n",
        "X_test_new = np.concatenate((X_test[:,:7], X_test[:,8:]), axis=1)\n",
        "X_train_new = np.concatenate((X_train[:,:7], X_train[:,8:]), axis=1)\n",
        "\n",
        "lr_new = LogisticRegression(max_iter=1000)\n",
        "xgb_new = xgboost.XGBClassifier(n_estimators=500, max_depth=2)\n",
        "lr_new.fit(X_train_new, Y_train)\n",
        "xgb_new.fit(X_train_new, Y_train)\n",
        "print(accuracy_score(lr_new.predict(X_test_new), Y_test))\n",
        "print(accuracy_score(xgb_new.predict(X_test_new), Y_test))\n",
        "\n",
        "cols = list(wine.columns[:7]) + list(wine.columns[8:])\n",
        "\n",
        "mask_new = shap.maskers.Independent(X_train_new)\n",
        "lr_explainer_new = shap.LinearExplainer(lr_new, mask_new, feature_names=cols)\n",
        "lr_shap_values_new = lr_explainer_new.shap_values(X_test_new)\n",
        "lr_shaps_new = lr_explainer_new(X_test_new)\n",
        "\n",
        "xgb_explainer_new = shap.TreeExplainer(xgb_new, X_train_new, feature_names=cols)\n",
        "xgb_shap_values_new = xgb_explainer_new.shap_values(X_test_new)\n",
        "xgb_shaps_new = xgb_explainer_new(X_test_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3x3wRmZguOO"
      },
      "outputs": [],
      "source": [
        "shap.decision_plot(lr_explainer_new.expected_value, lr_shap_values_new[ind], feature_names=cols[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlsXEsM14r5n"
      },
      "outputs": [],
      "source": [
        "shap.decision_plot(xgb_explainer_new.expected_value, xgb_shap_values_new[ind], feature_names=cols[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S99lqnpxsen"
      },
      "source": [
        "There are also additional functions you can look into at the [shap documentation](https://shap.readthedocs.io/en/latest/api.html) and examples via their [github page](https://github.com/shap/shap)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc2g8gmTzt17"
      },
      "source": [
        "## LIME\n",
        "\n",
        "Here we use LIME to get an interpretable model from our previously trained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZNNxxVCOA2G"
      },
      "outputs": [],
      "source": [
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train ,class_names=['Low Quality', 'High Quality'], feature_names = wine.columns[:11],\n",
        "                                                   #categorical_features=categorical_features,\n",
        "                                                   #categorical_names=categorical_names,\n",
        "                                                   kernel_width=3, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRj4yDmYj5Ic"
      },
      "source": [
        "Using the same data instance as before, we show the contribution of each feature for the prediction. This example limits the number of features to 5. Try and see what happens if you increase/decrease the number of features to include."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLfxVQBMYM_Q"
      },
      "outputs": [],
      "source": [
        "ind = 10\n",
        "exp = lime_explainer.explain_instance(X_test[ind], lr.predict_proba, num_features=5)\n",
        "exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXxz1JzZkNHV"
      },
      "source": [
        "We can also grab the rules we get from the interpretable model LIME creates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKn4xxe_jMiG"
      },
      "outputs": [],
      "source": [
        "exp.as_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfGycB_PkRzw"
      },
      "source": [
        "The code below just grabs the data instance and its corresponding feature values for you to compare against the rules above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWaHm7hlUUoJ"
      },
      "outputs": [],
      "source": [
        "list(zip(X_test[ind], wine.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RXGhncxsen"
      },
      "source": [
        "There are also more functions in LIME that you can look into through the [LIME documentation](https://lime-ml.readthedocs.io/en/latest/) and examples via the [github page](https://github.com/marcotcr/lime)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOUvBxTpWDx6"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "Here you are to apply the techniques from above to try and explain the output produced by a model.\n",
        "\n",
        "Think about questions such as, but not limited to:\n",
        "- Which parts of the data are mostly influencing the models output?\n",
        "- Are some parts unecessary of the data?\n",
        "- What can you do to improve explainability of the model?\n",
        "- Etc.\n",
        "\n",
        "Investigate, analyze, and possibly improve the model using the SHAP and LIME modules. Explain and show your steps as you go along."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUeKPHGQH5am"
      },
      "source": [
        "## Load the data, create and train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qd8KSAZH8yp"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import load, dump\n",
        "import pickle\n",
        "\n",
        "# Import dataset\n",
        "scaler = MinMaxScaler()\n",
        "dataset = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], dataset['target'], test_size=0.2, random_state=42)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Creating and training the model\n",
        "clf = MLPClassifier(hidden_layer_sizes = [100,100], alpha = 5, solver = 'lbfgs', max_iter = 1000).fit(X_train_scaled, y_train)\n",
        "\n",
        "print('Training score:', clf.score(X_train_scaled, y_train))\n",
        "print('Testing score:', clf.score(X_test_scaled, y_test))\n",
        "\n",
        "# Output should be\n",
        "#Training score: 0.9802197802197802\n",
        "#Testing score: 0.9736842105263158"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWUMZtK4IBAv"
      },
      "source": [
        "## Students code and text below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `MLPClassifier` could be considered a deep learning approach, however, the `DeepLearningExplainer` only supports `tensorflow` and `pytorch`. Hench the `KernelExplainer` was used here as it was a model agnostic approach. The only disadvantage it was slower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe2QYSZyxseo"
      },
      "outputs": [],
      "source": [
        "model_explainer = shap.explainers.KernelExplainer(\n",
        "    lambda x: clf.predict_proba(x)[..., 0], \n",
        "    X_train_scaled, \n",
        "    seed=0\n",
        ")\n",
        "model_shaps = model_explainer(X_test_scaled)\n",
        "model_shaps.feature_names = dataset[\"feature_names\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the SHAP results to see which features move the predictions more on the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.bar(model_shaps, max_display=model_shaps.data.shape[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the model on different features based on their shapley values. The model was be iterated one feature at a time to see how the performance changes.\n",
        "\n",
        "The model reached its stable result at 4 features for the test set. Though the prediction fluctuates from time to time on a single item, making the best model at 19 and 20 featuers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pruned_feature_indices = np.argsort(np.abs(model_shaps.values).mean(0))[::-1]\n",
        "pruned_feature_scores = []\n",
        "\n",
        "for n_features, _ in enumerate(pruned_feature_indices, 1):\n",
        "    pruned_X_train = X_train_scaled[:, pruned_feature_indices[:n_features]]\n",
        "    pruned_X_test = X_test_scaled[:, pruned_feature_indices[:n_features]]\n",
        "\n",
        "    pruned_clf = MLPClassifier(\n",
        "        hidden_layer_sizes = [100,100], \n",
        "        alpha = 5, \n",
        "        solver = 'lbfgs', \n",
        "        max_iter = 1000\n",
        "    ).fit(pruned_X_train, y_train)\n",
        "    pruned_feature_scores.append(pruned_clf.score(pruned_X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(pruned_feature_scores)\n",
        "plt.xlabel(\"N Features\")\n",
        "plt.ylabel(\"Model Score\")\n",
        "plt.title(\"N Features vs Model Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the correlated features and see how they impact the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clustering = shap.utils.hclust(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.bar(\n",
        "    model_shaps, \n",
        "    clustering=clustering, \n",
        "    clustering_cutoff=0.1,\n",
        "    max_display=model_shaps.data.shape[-1]\n",
        ") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the model on the uncorrelated features had the same performance as the base model. In this case it means one can focus on these uncorrelated features to save performance and reduce model complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_features = {\n",
        "    \"worst concave points\",\n",
        "    \"worst radius\",\n",
        "    \"mean concave points\",\n",
        "    \"worst texture\",\n",
        "    \"worst concavity\",\n",
        "    \"mean texture\",\n",
        "    \"worst smoothness\",\n",
        "    \"worst symmetry\",\n",
        "    \"radius error\",\n",
        "    \"mean fractal dimension\",\n",
        "    \"area error\",\n",
        "    \"compactness error\",\n",
        "    \"mean fractal dimension\",\n",
        "    \"mean compactness\",\n",
        "}\n",
        "corr_feature_indices = np.asarray([\n",
        "    idx for idx, n in enumerate(dataset[\"feature_names\"]) \n",
        "    if n in corr_features\n",
        "])\n",
        "corr_X_train = X_train_scaled[:, corr_feature_indices]\n",
        "corr_X_test = X_test_scaled[:, corr_feature_indices]\n",
        "\n",
        "corr_clf = MLPClassifier(\n",
        "    hidden_layer_sizes = [100,100], \n",
        "    alpha = 5, \n",
        "    solver = 'lbfgs',\n",
        "    max_iter = 1000\n",
        ").fit(corr_X_train, y_train)\n",
        "\n",
        "print('Training score:', corr_clf.score(corr_X_train, y_train))\n",
        "print('Testing score:', corr_clf.score(corr_X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the summary plot to see the impact of the features to shapley values for each sample. This should provide an idea how the model generates its predictions on a general level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.summary_plot(model_shaps.values, X_test_scaled, feature_names=dataset[\"feature_names\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In general, the summary plot shows that the features are high on one side and low on the other side of the shapley values. This means that the features used by the model are highly separable and are linear.\n",
        "\n",
        "The linear model performed well on the test set initial model. The only disadvantage was missing 5 data points on the train set. However, there was also an advantage that this model is more interpretable and could be easily understood while only giving up a small amount of performance. The simplicity of the model also means it was more efficient computationally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linear_clf = LogisticRegression().fit(X_train_scaled, y_train)\n",
        "\n",
        "print('Training score:', linear_clf.score(X_train_scaled, y_train))\n",
        "print('Testing score:', linear_clf.score(X_test_scaled, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A decision tree ensemble was also tested and also performed well though there are signs of overfitting. It missing a prediction compared to the `MLPClassifier` on the test set while also being more explainable compared to it. Though this adds more complexity compared to the linear model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree_clf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    random_state=0\n",
        ").fit(X_train_scaled, y_train)\n",
        "\n",
        "print('Training score:', tree_clf.score(X_train_scaled, y_train))\n",
        "print('Testing score:', tree_clf.score(X_test_scaled, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
